name: Sync Upstream, Validate Links, and Push to TVB

# 定时任务：每隔一天运行一次
on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 */2 * *'

jobs:
  sync_validate_push:
    runs-on: ubuntu-latest
    
    # 定义要操作的仓库信息
    env:
      FORK_REPO: ${{ github.repository_owner }}/Tvbox1  # 你的Fork仓库路径
      UPSTREAM_REPO: hd9211/Tvbox1 # 源仓库路径
      TARGET_REPO: ${{ github.repository_owner }}/tvb # 目标私有仓库路径

    steps:
      - name: 1. Checkout YOUR FORK Repository (Tvbox1)
        uses: actions/checkout@v4
        with:
          # 使用 PAT_FOR_FORK 来访问和修改你的 Tvbox1 Fork
          token: ${{ secrets.PAT_FOR_FORK }}
          repository: ${{ env.FORK_REPO }}
          path: fork-repo # 签出到 'fork-repo' 目录

      - name: 2. Setup Git User in Fork Repo
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

      - name: 3. Sync from Upstream
        id: sync_step
        working-directory: ./fork-repo # 在你的Fork仓库目录中执行
        run: |
          # 添加源仓库
          git remote add upstream https://github.com/${{ env.UPSTREAM_REPO }}.git
          git fetch upstream
          
          # 检查更新
          LOCAL=$(git rev-parse @)
          REMOTE=$(git rev-parse upstream/main)
          
          if [ "$LOCAL" = "$REMOTE" ]; then
            echo "✅ Fork is up-to-date. No new commits from upstream."
            echo "HAS_UPDATES=false" >> $GITHUB_ENV
          else
            echo "🔥 Upstream has updates. Syncing..."
            # 强制同步并推送到你的 Fork
            git reset --hard upstream/main
            git push origin main --force
            echo "HAS_UPDATES=true" >> $GITHUB_ENV
          fi

      # -------------------------------------------------------------------
      # 后续步骤仅在有更新时执行
      # -------------------------------------------------------------------

      - name: 4. Setup Python
        if: env.HAS_UPDATES == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: 5. Install Python Dependencies
        if: env.HAS_UPDATES == 'true'
        run: pip install requests

      - name: 6. Create Validation Script
        if: env.HAS_UPDATES == 'true'
        run: |
          # 脚本内容不变，仍然创建在Action的根工作目录
          cat << 'EOF' > validate_links.py
          import json
          import requests
          import sys
          import os
          from concurrent.futures import ThreadPoolExecutor

          HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
          TIMEOUT = 8

          def check_url(url):
              # ... (Python 脚本代码不变，为节省空间省略，请使用之前完整的代码) ...
              if not url or not url.startswith(('http://', 'https://')):
                  print(f"SKIPPING: Invalid URL format {url}")
                  return False, url
              try:
                  response = requests.get(url, timeout=TIMEOUT, headers=HEADERS, allow_redirects=True, stream=True)
                  if 200 <= response.status_code < 400:
                      print(f"SUCCESS: {url} (Status: {response.status_code})")
                      return True, url
                  else:
                      print(f"FAIL: {url} (Status: {response.status_code})")
                      return False, url
              except requests.RequestException as e:
                  print(f"ERROR: {url} ({e})")
                  return False, url

          def process_file(filepath):
              if not os.path.exists(filepath):
                  print(f"File not found: {filepath}. Skipping.")
                  return

              print(f"\nProcessing file: {filepath}")
              try:
                  with open(filepath, 'r', encoding='utf-8') as f:
                      data = json.load(f)
              except Exception as e:
                  print(f"Error reading or decoding {filepath}: {e}")
                  return

              key_list = None
              if 'sites' in data and isinstance(data['sites'], list):
                  key_list = 'sites'
              elif 'urls' in data and isinstance(data['urls'], list):
                  key_list = 'urls'
              else:
                  print(f"Unknown JSON structure in {filepath}. Skipping.")
                  return
              
              items = data.get(key_list, [])
              urls_to_check = []
              for item in items:
                  if isinstance(item, dict):
                      url = item.get('url') or item.get('api')
                      if url:
                          urls_to_check.append((url, item))
                      else:
                          print(f"SKIPPING item: No 'url' or 'api' key found in {item}")

              if not urls_to_check:
                  print(f"No URLs found to check in {filepath}.")
                  return

              valid_items = []
              with ThreadPoolExecutor(max_workers=10) as executor:
                  results = executor.map(check_url, [u[0] for u in urls_to_check])
                  
                  for (is_valid, url), item in zip(results, [u[1] for u in urls_to_check]):
                      if is_valid:
                          valid_items.append(item)

              data[key_list] = valid_items
              try:
                  with open(filepath, 'w', encoding='utf-8') as f:
                      json.dump(data, f, ensure_ascii=False, indent=4)
                  print(f"Processed {filepath}. Kept {len(valid_items)} / {len(items)} items.")
              except Exception as e:
                  print(f"Error writing processed file {filepath}: {e}")

          if __name__ == "__main__":
              files_to_process = sys.argv[1:]
              if not files_to_process:
                  print("No files specified.")
                  sys.exit(1)
              
              for f in files_to_process:
                  process_file(f)
          EOF


      - name: 7. Run Validation Script (on Fork files)
        if: env.HAS_UPDATES == 'true'
        run: |
          # 从 fork-repo 目录读取文件，在 Action 根目录运行脚本
          python validate_links.py fork-repo/优质.json fork-repo/cr.json fork-repo/duocang1.json

      - name: 8. Checkout Private Repo 'tvb'
        if: env.HAS_UPDATES == 'true'
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT_FOR_TVB }} 
          repository: ${{ env.TARGET_REPO }}
          path: tvb-repo
          
      - name: 9. Copy Filtered Files
        if: env.HAS_UPDATES == 'true'
        run: |
          # 确保目标目录存在（解决上次的错误）
          echo "Ensuring target directory exists..."
          mkdir -p tvb-repo/tvb/TVbox/
          
          echo "Copying validated files to tvb-repo/tvb/TVbox/..."
          # 注意：现在源文件路径是 fork-repo/...
          cp fork-repo/优质.json tvb-repo/tvb/TVbox/
          cp fork-repo/cr.json tvb-repo/tvb/TVbox/
          cp fork-repo/duocang1.json tvb-repo/tvb/TVbox/
          
      - name: 10. Commit and Push to 'tvb'
        if: env.HAS_UPDATES == 'true'
        run: |
          cd tvb-repo
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          if [ -n "$(git status --porcelain)" ]; then
            git add .
            git commit -m "chore: Auto-update and validate Tvbox sources"
            git push
            echo "✅ Successfully pushed validated files to tvb repo."
          else
            echo "ℹ️ No changes to commit."
          fi
